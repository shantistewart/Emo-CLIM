{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset root directory:\n",
    "DATA_DIR = \"/proj/systewar/datasets/IMAC/image_dataset\"\n",
    "# label subdirectories:\n",
    "SUBDIR_NAMES = [\"excitement\", \"anger\", \"fear\", \"amusement\", \"awe\", \"contentment\", \"disgust\", \"sadness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script options:\n",
    "N_class_val = 50     # number of samples per class in validation set\n",
    "N_class_test = 200     # number of samples per class in test set\n",
    "metadata_files_split = {\n",
    "    \"train\": \"/proj/systewar/datasets/IMAC/image_dataset/metadata_train.csv\",\n",
    "    \"val\": \"/proj/systewar/datasets/IMAC/image_dataset/metadata_val.csv\",\n",
    "    \"test\": \"/proj/systewar/datasets/IMAC/image_dataset/metadata_test.csv\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset label directories:\n",
    "subdir_names = [name for name in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, name))]\n",
    "subdir_names = [name for name in subdir_names if name in SUBDIR_NAMES]\n",
    "assert subdir_names == SUBDIR_NAMES, \"Error with listing dataset subdirectories.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of dataset: 21829\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21829 entries, 0 to 21828\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  21829 non-null  object\n",
      " 1   file_name    21829 non-null  object\n",
      " 2   label        21829 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 511.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# get all image file paths:\n",
    "subdirs = []\n",
    "image_file_names = []\n",
    "emotion_labels = []\n",
    "for label in subdir_names:\n",
    "    # get file_names:\n",
    "    subdir_path = os.path.join(DATA_DIR, label)\n",
    "    file_names = [name for name in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, name))]\n",
    "    n_images = len(file_names)\n",
    "    # save metadata:\n",
    "    subdirs += n_images * [label]\n",
    "    image_file_names += file_names\n",
    "    emotion_labels += n_images * [label]\n",
    "\n",
    "# create dataframe:\n",
    "metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"subdir_name\": subdirs,\n",
    "        \"file_name\": image_file_names,\n",
    "        \"label\": emotion_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Total size of dataset: {}\".format(metadata.shape[0]))\n",
    "print()\n",
    "print(metadata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contentment images: 5130\n",
      "Number of amusement images: 4724\n",
      "Number of awe images: 2881\n",
      "Number of excitement images: 2725\n",
      "Number of sadness images: 2633\n",
      "Number of disgust images: 1591\n",
      "Number of anger images: 1176\n",
      "Number of fear images: 969\n"
     ]
    }
   ],
   "source": [
    "# get label counts:\n",
    "label_counts = metadata[\"label\"].value_counts()\n",
    "for label in metadata[\"label\"].value_counts().index:\n",
    "    print(\"Number of {} images: {}\".format(label, label_counts[label]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1600 entries, 5097 to 20417\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  1600 non-null   object\n",
      " 1   file_name    1600 non-null   object\n",
      " 2   label        1600 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 50.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# construct stratified test set by randomly sampling from each class:\n",
    "metadata_test_groups = metadata.groupby(by=\"label\", axis=\"index\")\n",
    "metadata_test = metadata_test_groups.sample(n=N_class_test, random_state=42)\n",
    "print(metadata_test.info())\n",
    "\n",
    "# sanity check:\n",
    "for count in metadata_test[\"label\"].value_counts():\n",
    "    assert count == N_class_test, \"Error with creating stratified test set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400 entries, 7392 to 19945\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  400 non-null    object\n",
      " 1   file_name    400 non-null    object\n",
      " 2   label        400 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# remove test set:\n",
    "metadata_train_val = metadata.drop(index=list(metadata_test.index))\n",
    "\n",
    "# construct stratified validation set by randomly sampling from each class:\n",
    "metadata_val_groups = metadata_train_val.groupby(by=\"label\", axis=\"index\")\n",
    "metadata_val = metadata_val_groups.sample(n=N_class_val, random_state=42)\n",
    "print(metadata_val.info())\n",
    "\n",
    "# sanity check:\n",
    "for count in metadata_val[\"label\"].value_counts():\n",
    "    assert count == N_class_val, \"Error with creating stratified validation set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19829 entries, 0 to 21828\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  19829 non-null  object\n",
      " 1   file_name    19829 non-null  object\n",
      " 2   label        19829 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 619.7+ KB\n",
      "None\n",
      "\n",
      "contentment    4880\n",
      "amusement      4474\n",
      "awe            2631\n",
      "excitement     2475\n",
      "sadness        2383\n",
      "disgust        1341\n",
      "anger           926\n",
      "fear            719\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# construct training set:\n",
    "metadata_train = metadata_train_val.drop(index=list(metadata_val.index))\n",
    "print(metadata_train.info())\n",
    "print()\n",
    "print(metadata_train[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all subsets are disjoint:\n",
    "metadata_subsets = [metadata_train, metadata_val, metadata_test]\n",
    "subset_names = list(metadata_files_split.keys())\n",
    "for subset_1, name_1 in zip(metadata_subsets, subset_names):\n",
    "    for subset_2, name_2 in zip(metadata_subsets, subset_names):\n",
    "        if name_1 != name_2:\n",
    "            assert set(subset_1.index).isdisjoint(set(subset_2.index)), \"{} and {} are not disjoint\".format(name_1, name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices:\n",
    "metadata_train = metadata_train.reset_index(drop=True)\n",
    "metadata_val = metadata_val.reset_index(drop=True)\n",
    "metadata_test = metadata_test.reset_index(drop=True)\n",
    "\n",
    "# sanity checks:\n",
    "assert metadata.shape[0] == metadata_train.shape[0] + metadata_val.shape[0] + metadata_test.shape[0], \"Subset set sizes don't add up.\"\n",
    "# check that all subsets are disjoint:\n",
    "metadata_subsets = [metadata_train, metadata_val, metadata_test]\n",
    "subset_names = list(metadata_files_split.keys())\n",
    "for subset_1, name_1 in zip(metadata_subsets, subset_names):\n",
    "    for subset_2, name_2 in zip(metadata_subsets, subset_names):\n",
    "        if name_1 != name_2:\n",
    "            assert set(subset_1[\"file_name\"].tolist()).isdisjoint(set(subset_2[\"file_name\"].tolist())), \"{} and {} are not disjoint\".format(name_1, name_2)\n",
    "# more sanity checks:\n",
    "class_counts_all = metadata[\"label\"].value_counts()\n",
    "class_counts_train = metadata_train[\"label\"].value_counts()\n",
    "class_counts_val = metadata_val[\"label\"].value_counts()\n",
    "class_counts_test = metadata_test[\"label\"].value_counts()\n",
    "for class_label in metadata_test_groups.groups.keys():\n",
    "    assert class_counts_all[class_label] == class_counts_train[class_label] + class_counts_val[class_label] + class_counts_test[class_label], \"Error with splitting dataset.\"\n",
    "\n",
    "# save to file:\n",
    "metadata_train.to_csv(metadata_files_split[\"train\"], index=False)\n",
    "metadata_val.to_csv(metadata_files_split[\"val\"], index=False)\n",
    "metadata_test.to_csv(metadata_files_split[\"test\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-queries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
